<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Concordance as a Measure of Model Fit" />
<meta property="og:description" content="The whole idea of concordance as a success metric makes a lot more sense when you look at the definition of the word itself.
 an alphabetical list of the words (especially the important ones) present in a text, usually with citations of the passages concerned.
 Simply put, the Concordance Index is a measure of how well-sorted our predictions are.
How we actually arrive at this measure requires a little more digging." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://napsterinblue.github.io/notes/stats/survival_analysis/concordance/" />



<meta property="article:published_time" content="2020-04-07T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2020-04-07T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Concordance as a Measure of Model Fit"/>
<meta name="twitter:description" content="The whole idea of concordance as a success metric makes a lot more sense when you look at the definition of the word itself.
 an alphabetical list of the words (especially the important ones) present in a text, usually with citations of the passages concerned.
 Simply put, the Concordance Index is a measure of how well-sorted our predictions are.
How we actually arrive at this measure requires a little more digging."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Concordance as a Measure of Model Fit",
  "url": "https://napsterinblue.github.io/notes/stats/survival_analysis/concordance/",
  "wordCount": "2415",
  "datePublished": "2020-04-07T00:00:00&#43;00:00",
  "dateModified": "2020-04-07T00:00:00&#43;00:00",
  "author": {
    "@type": "Person",
    "name": ""
  }
}
</script> 

    <title>Concordance as a Measure of Model Fit</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://napsterinblue.github.io/notes/css/custom.css" rel="stylesheet">
    <link href="https://napsterinblue.github.io/notes/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Data Science Notes" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://napsterinblue.github.io">Movies, Metrics, Musings</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://napsterinblue.github.io/pages/about.html" title="About">About</a></li>
                    <li><a href="https://napsterinblue.github.io/archives.html" title="Archive">Archive</a></li>
                    <li><a href="https://napsterinblue.github.io/pages/resources.html" title="Resources">Resources</a></li>
                    <li><a href="https://napsterinblue.github.io/notes/" title="Notes">My Notes</a></li>

                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Concordance as a Measure of Model Fit</h1>
    <div class="technical_note_date">
      <time datetime=" 2020-04-07T00:00:00Z "> 07 Apr 2020</time>
    </div>
  </header>
  <div class="content">
  

<p>The whole idea of concordance as a success metric makes a lot more sense when you look at the definition of the word itself.</p>

<blockquote>
<p>an alphabetical list of the words (especially the important ones) present in a text, usually with citations of the passages concerned.</p>
</blockquote>

<p>Simply put, the Concordance Index is a measure of how well-sorted our predictions are.</p>

<p>How we actually arrive at this measure requires a little more digging.</p>

<h2 id="a-motivating-example">A Motivating Example</h2>

<p>I almost never copy someone&rsquo;s tutorial so brazenly, so let the fact that I&rsquo;m about to be a testiment to how helpful <a href="https://medium.com/analytics-vidhya/churn-prediction-in-a-telco-70ba5aa12f70">this Medium post was.</a> I&rsquo;m going to use the same toy dataset and distill the author&rsquo;s takeaways, while also adding my own and a couple clarifying snippets of code.</p>

<p>Essentially, we&rsquo;ve got a list of 5 people experiencing an churn in some order&ndash; for simplicity, <code>1, 2, 3, 4, 5</code>. We do Data Stuff to the the inputs and arrive at predictions for when each person will churn, as follows.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">lifelines.utils</span> <span class="kn">import</span> <span class="n">concordance_index</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Alice&#39;</span><span class="p">,</span> <span class="s1">&#39;Bob&#39;</span><span class="p">,</span> <span class="s1">&#39;Carol&#39;</span><span class="p">,</span> <span class="s1">&#39;Dave&#39;</span><span class="p">,</span> <span class="s1">&#39;Eve&#39;</span><span class="p">]</span>
<span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;churn times&#39;</span><span class="p">:</span> <span class="n">events</span><span class="p">,</span>
                        <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">preds</span><span class="p">},</span>
                  <span class="n">index</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>

<span class="n">df</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>churn times</th>
      <th>predictions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alice</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Bob</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Carol</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Dave</th>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>Eve</th>
      <td>5</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

<p>Perfect prediction. We expect a good score. Lo and behold, <code>1.0</code> is the highest this index goes.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>1.0
</code></pre>

<h3 id="ordering">Ordering</h3>

<p>However, one interesting consequence of this is that the magnitude of our predictions doesn&rsquo;t matter, as long as they&rsquo;re sorted correctly. Imagine instead, that the predictions were on the scale of <code>100s</code>, not <code>1s</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>1.0
</code></pre>

<p>Or followed some monotonically-increasing function.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">events</span><span class="p">)</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>1.0
</code></pre>

<p>Indeed, the stated purpose of the index is to evaluate how well the two lists are sorted. Watch what happens when it gets the last two predictions wrong.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>0.9
</code></pre>

<p>Or swaps the first and last record</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>0.3
</code></pre>

<p>Or gets it entirely backwards</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>0.0
</code></pre>

<p>How is this being calculated?</p>

<h3 id="taking-a-peak">Taking a peak</h3>

<p>Essentially, the Concordance Index sorts our <code>names</code> by the order of <code>events</code>, and takes all before-and-after pairs. Call this set <code>A</code>. Then it does the same thing when sorting by <code>predictions</code> to make set <code>B</code>. Then it takes the intersection of the two to make a new set <code>C</code>. Finally, the Concordance Index is the ratio of the lengths of <code>C</code> and <code>A</code>&ndash; a perfect prediction will have generated the same set <code>B</code> making the intersection one-to-one. Similarly <code>C</code> will contain less records the more <code>B</code> generated incorrect pairs.</p>

<p>For example:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>

<span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>0.8
</code></pre>

<p>Under the hood, you can think of having a function that does the following</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">generate_name_pairs</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
    <span class="c1"># sort (name, value) pairs by values</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">values</span><span class="p">)),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">set_</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">first_person</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
        <span class="c1"># don&#39;t want (Alice, Alice)</span>
        <span class="k">for</span> <span class="n">second_person</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">set_</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">first_person</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">second_person</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">set_</span>

<span class="k">print</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">events</span><span class="p">)</span>
<span class="n">generate_name_pairs</span><span class="p">(</span><span class="n">events</span><span class="p">)</span></code></pre></div>
<pre><code>['Alice', 'Bob', 'Carol', 'Dave', 'Eve']
[1, 2, 3, 4, 5]





{('Alice', 'Bob'),
 ('Alice', 'Carol'),
 ('Alice', 'Dave'),
 ('Alice', 'Eve'),
 ('Bob', 'Carol'),
 ('Bob', 'Dave'),
 ('Bob', 'Eve'),
 ('Carol', 'Dave'),
 ('Carol', 'Eve'),
 ('Dave', 'Eve')}
</code></pre>

<p>Generating our sets as described above, we can see that <code>C</code> does, indeed have a smaller length than <code>A</code> and <code>B</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">A</span> <span class="o">=</span> <span class="n">generate_name_pairs</span><span class="p">(</span><span class="n">events</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">generate_name_pairs</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">C</span><span class="p">)</span></code></pre></div>
<pre><code>{('Carol', 'Eve'), ('Alice', 'Eve'), ('Bob', 'Dave'), ('Alice', 'Carol'), ('Bob', 'Carol'), ('Carol', 'Dave'), ('Bob', 'Eve'), ('Dave', 'Eve'), ('Alice', 'Bob'), ('Alice', 'Dave')} 

{('Carol', 'Eve'), ('Alice', 'Eve'), ('Bob', 'Dave'), ('Alice', 'Carol'), ('Carol', 'Dave'), ('Eve', 'Dave'), ('Bob', 'Eve'), ('Carol', 'Bob'), ('Alice', 'Bob'), ('Alice', 'Dave')} 

{('Carol', 'Eve'), ('Alice', 'Eve'), ('Bob', 'Dave'), ('Carol', 'Dave'), ('Alice', 'Carol'), ('Bob', 'Eve'), ('Alice', 'Bob'), ('Alice', 'Dave')}





(10, 10, 8)
</code></pre>

<p>Investigating the difference, is straight-forward and expected. We intentionally swapped two pairs in this example.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">A</span><span class="p">))</span></code></pre></div>
<pre><code>{('Bob', 'Carol'), ('Dave', 'Eve')}
{('Eve', 'Dave'), ('Carol', 'Bob')}
</code></pre>

<p>And taking the ratio of the lengths, we get <code>0.8</code></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span></code></pre></div>
<pre><code>0.8
</code></pre>

<p>Or we can do away with all of this set business and just use the function!</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span></code></pre></div>
<pre><code>0.8
</code></pre>

<p><strong>Note</strong>: This isn&rsquo;t actually how it&rsquo;s implemented on the backend. The pair-construction alone makes the algorithm <code>O(n^2)</code>. In reality, <code>lifelines</code> does some clever sorting vector operations to get performance to <code>O(n log(n))</code>. Use <code>lifelines</code>, lol.</p>

<h3 id="on-censoring">On Censoring</h3>

<p>One element we&rsquo;ve neglected to mention until now is the way that this index interacts with censored data. Imagine that in our dataset, we never observed Churn for Carol. Now our lists look like</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">obs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">]</span></code></pre></div>
<p>and using the third, <code>events_observed</code>, argument in generating the index, we&rsquo;ve got.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">concordance_index</span><span class="p">(</span><span class="n">events</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span></code></pre></div>
<pre><code>0.75
</code></pre>

<p>This is because we repeat the exercise after throwing out every pair starting with a censored data point.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">new_A</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;Carol&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">))</span>
<span class="n">new_A</span></code></pre></div>
<pre><code>{('Alice', 'Bob'),
 ('Alice', 'Carol'),
 ('Alice', 'Dave'),
 ('Alice', 'Eve'),
 ('Bob', 'Carol'),
 ('Bob', 'Dave'),
 ('Bob', 'Eve'),
 ('Dave', 'Eve')}
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">new_C</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;Carol&#39;</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
<span class="n">new_C</span></code></pre></div>
<pre><code>{('Alice', 'Bob'),
 ('Alice', 'Carol'),
 ('Alice', 'Dave'),
 ('Alice', 'Eve'),
 ('Bob', 'Dave'),
 ('Bob', 'Eve')}
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">new_C</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_A</span><span class="p">)</span></code></pre></div>
<pre><code>0.75
</code></pre>

<p>Note, we don&rsquo;t also toss pairs <em>ending</em> in &lsquo;Carol&rsquo;. This should track, intuitively&ndash; just because we don&rsquo;t know how long after the observation window Carol took to churn doesn&rsquo;t mean that Alice churning right out of the gate didn&rsquo;t happen, regardless.</p>

<h2 id="on-real-data">On Real Data</h2>

<p>Now, to better-ground ourselves in a pratical example, let&rsquo;s look at the built-in <code>lifelines</code> dataset that investigates the duration of a country&rsquo;s leadership.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">lifelines.datasets</span> <span class="kn">import</span> <span class="n">load_dd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">load_dd</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ctryname</th>
      <th>cowcode2</th>
      <th>politycode</th>
      <th>un_region_name</th>
      <th>un_continent_name</th>
      <th>ehead</th>
      <th>leaderspellreg</th>
      <th>democracy</th>
      <th>regime</th>
      <th>start_year</th>
      <th>duration</th>
      <th>observed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>700</td>
      <td>700.0</td>
      <td>Southern Asia</td>
      <td>Asia</td>
      <td>Mohammad Zahir Shah</td>
      <td>Mohammad Zahir Shah.Afghanistan.1946.1952.Mona...</td>
      <td>Non-democracy</td>
      <td>Monarchy</td>
      <td>1946</td>
      <td>7</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghanistan</td>
      <td>700</td>
      <td>700.0</td>
      <td>Southern Asia</td>
      <td>Asia</td>
      <td>Sardar Mohammad Daoud</td>
      <td>Sardar Mohammad Daoud.Afghanistan.1953.1962.Ci...</td>
      <td>Non-democracy</td>
      <td>Civilian Dict</td>
      <td>1953</td>
      <td>10</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Afghanistan</td>
      <td>700</td>
      <td>700.0</td>
      <td>Southern Asia</td>
      <td>Asia</td>
      <td>Mohammad Zahir Shah</td>
      <td>Mohammad Zahir Shah.Afghanistan.1963.1972.Mona...</td>
      <td>Non-democracy</td>
      <td>Monarchy</td>
      <td>1963</td>
      <td>10</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Afghanistan</td>
      <td>700</td>
      <td>700.0</td>
      <td>Southern Asia</td>
      <td>Asia</td>
      <td>Sardar Mohammad Daoud</td>
      <td>Sardar Mohammad Daoud.Afghanistan.1973.1977.Ci...</td>
      <td>Non-democracy</td>
      <td>Civilian Dict</td>
      <td>1973</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Afghanistan</td>
      <td>700</td>
      <td>700.0</td>
      <td>Southern Asia</td>
      <td>Asia</td>
      <td>Nur Mohammad Taraki</td>
      <td>Nur Mohammad Taraki.Afghanistan.1978.1978.Civi...</td>
      <td>Non-democracy</td>
      <td>Civilian Dict</td>
      <td>1978</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Breaking out by <code>regime</code> and fitting simple Kaplan-Meier curves, we can see a pattern in survival rates, relative to government type</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">lifelines</span> <span class="kn">import</span> <span class="n">KaplanMeierFitter</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">kmf</span> <span class="o">=</span> <span class="n">KaplanMeierFitter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;regime&#39;</span><span class="p">):</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">])</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span></code></pre></div>
<pre><code>Populating the interactive namespace from numpy and matplotlib
</code></pre>

<p><img src="concordance_38_1.png" alt="png" /></p>

<p>We&rsquo;ll use this to make a simple categorical binning</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">regime_mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Monarchy&#39;</span><span class="p">:</span> <span class="s1">&#39;Monarchy&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Civilian Dict&#39;</span><span class="p">:</span> <span class="s1">&#39;Dict&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Military Dict&#39;</span><span class="p">:</span> <span class="s1">&#39;Dict&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Parliamentary Dem&#39;</span><span class="p">:</span> <span class="s1">&#39;Dem&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Presidential Dem&#39;</span><span class="p">:</span> <span class="s1">&#39;Dem&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Mixed Dem&#39;</span><span class="p">:</span> <span class="s1">&#39;Dem&#39;</span>
<span class="p">}</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;regime_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;regime&#39;</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">regime_mapping</span><span class="p">)</span></code></pre></div>
<p>Probably also worth looking at this by continent, it seems</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">kmf</span> <span class="o">=</span> <span class="n">KaplanMeierFitter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">):</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">])</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">ci_show</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></div>
<p><img src="concordance_42_0.png" alt="png" /></p>

<p>Finally, let&rsquo;s do our favorite year-to-decade <code>pandas</code> trick for good measure.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s1">&#39;decade&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;start_year&#39;</span><span class="p">]</span> <span class="o">//</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span></code></pre></div>
<p>We&rsquo;ll lop off the other fields, dummy out the categorical features, and</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">trimmed</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">,</span> <span class="s1">&#39;decade&#39;</span><span class="p">,</span> <span class="s1">&#39;duration&#39;</span><span class="p">,</span> <span class="s1">&#39;regime_type&#39;</span><span class="p">,</span> <span class="s1">&#39;observed&#39;</span><span class="p">]]</span>

<span class="n">trimmed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">trimmed</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">trimmed</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>decade</th>
      <th>duration</th>
      <th>observed</th>
      <th>un_continent_name_Americas</th>
      <th>un_continent_name_Asia</th>
      <th>un_continent_name_Europe</th>
      <th>un_continent_name_Oceania</th>
      <th>regime_type_Dict</th>
      <th>regime_type_Monarchy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1940</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1950</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1960</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1970</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1970</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Fitting a Cox model to it, we&rsquo;ve got a concordance score of <code>0.64</code>. Not awful. We barely tried, so better-than-random using like two features is good enough for me on this one.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">lifelines</span> <span class="kn">import</span> <span class="n">CoxPHFitter</span>

<span class="n">cph</span> <span class="o">=</span> <span class="n">CoxPHFitter</span><span class="p">(</span><span class="n">penalizer</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">cph</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trimmed</span><span class="p">,</span> <span class="s1">&#39;duration&#39;</span><span class="p">,</span> <span class="s1">&#39;observed&#39;</span><span class="p">)</span>

<span class="n">cph</span><span class="o">.</span><span class="n">print_summary</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <tbody>
    <tr>
      <th>model</th>
      <td>lifelines.CoxPHFitter</td>
    </tr>
    <tr>
      <th>duration col</th>
      <td>'duration'</td>
    </tr>
    <tr>
      <th>event col</th>
      <td>'observed'</td>
    </tr>
    <tr>
      <th>penalizer</th>
      <td>0.001</td>
    </tr>
    <tr>
      <th>l1 ratio</th>
      <td>0</td>
    </tr>
    <tr>
      <th>baseline estimation</th>
      <td>breslow</td>
    </tr>
    <tr>
      <th>number of observations</th>
      <td>1808</td>
    </tr>
    <tr>
      <th>number of events observed</th>
      <td>1468</td>
    </tr>
    <tr>
      <th>partial log-likelihood</th>
      <td>-9578.78</td>
    </tr>
    <tr>
      <th>time fit was run</th>
      <td>2020-04-08 14:20:45 UTC</td>
    </tr>
  </tbody>
</table>
</div><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef</th>
      <th>exp(coef)</th>
      <th>se(coef)</th>
      <th>coef lower 95%</th>
      <th>coef upper 95%</th>
      <th>exp(coef) lower 95%</th>
      <th>exp(coef) upper 95%</th>
      <th>z</th>
      <th>p</th>
      <th>-log2(p)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>decade</th>
      <td>-0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>-0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>-0.19</td>
      <td>0.85</td>
      <td>0.23</td>
    </tr>
    <tr>
      <th>un_continent_name_Americas</th>
      <td>0.18</td>
      <td>1.19</td>
      <td>0.09</td>
      <td>-0.01</td>
      <td>0.36</td>
      <td>0.99</td>
      <td>1.44</td>
      <td>1.90</td>
      <td>0.06</td>
      <td>4.12</td>
    </tr>
    <tr>
      <th>un_continent_name_Asia</th>
      <td>0.25</td>
      <td>1.28</td>
      <td>0.09</td>
      <td>0.07</td>
      <td>0.42</td>
      <td>1.07</td>
      <td>1.53</td>
      <td>2.69</td>
      <td>0.01</td>
      <td>7.12</td>
    </tr>
    <tr>
      <th>un_continent_name_Europe</th>
      <td>0.43</td>
      <td>1.54</td>
      <td>0.09</td>
      <td>0.25</td>
      <td>0.61</td>
      <td>1.29</td>
      <td>1.84</td>
      <td>4.74</td>
      <td>&lt;0.005</td>
      <td>18.85</td>
    </tr>
    <tr>
      <th>un_continent_name_Oceania</th>
      <td>0.10</td>
      <td>1.10</td>
      <td>0.13</td>
      <td>-0.17</td>
      <td>0.36</td>
      <td>0.85</td>
      <td>1.43</td>
      <td>0.72</td>
      <td>0.47</td>
      <td>1.09</td>
    </tr>
    <tr>
      <th>regime_type_Dict</th>
      <td>-0.77</td>
      <td>0.46</td>
      <td>0.07</td>
      <td>-0.91</td>
      <td>-0.63</td>
      <td>0.40</td>
      <td>0.53</td>
      <td>-10.57</td>
      <td>&lt;0.005</td>
      <td>84.40</td>
    </tr>
    <tr>
      <th>regime_type_Monarchy</th>
      <td>-1.97</td>
      <td>0.14</td>
      <td>0.23</td>
      <td>-2.41</td>
      <td>-1.53</td>
      <td>0.09</td>
      <td>0.22</td>
      <td>-8.72</td>
      <td>&lt;0.005</td>
      <td>58.36</td>
    </tr>
  </tbody>
</table><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <tbody>
    <tr>
      <th>Concordance</th>
      <td>0.64</td>
    </tr>
    <tr>
      <th>Log-likelihood ratio test</th>
      <td>335.01 on 7 df</td>
    </tr>
    <tr>
      <th>-log2(p) of ll-ratio test</th>
      <td>224.90</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="distribution-shape">Distribution shape</h3>

<p>We can use the base hazard function of the Cox model to math our way to the base survival function</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cph</span><span class="o">.</span><span class="n">baseline_survival_</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span></code></pre></div>
<p><img src="concordance_50_0.png" alt="png" /></p>

<p>Investigating, it looks like it <em>sort of</em> fits the right shape. Looks like it doesn&rsquo;t drop off fast enough, though.</p>

<p>The actual durations, for reference:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">trimmed</span><span class="p">[</span><span class="n">trimmed</span><span class="p">[</span><span class="s1">&#39;observed&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">][</span><span class="s1">&#39;duration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span></code></pre></div>
<p><img src="concordance_52_0.png" alt="png" /></p>

<h3 id="expectations">Expectations</h3>

<p>The Expectation of the model has an important interpretation in this context&ndash; the predicted churn/death of a given record.</p>

<p>Taking the expectation of all of our trimmed data, we can see a spike at the <code>10-15</code> range, which matches our &ldquo;not dropping off fast enough&rdquo; interpretation.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cph</span><span class="o">.</span><span class="n">predict_expectation</span><span class="p">(</span><span class="n">trimmed</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">);</span></code></pre></div>
<p><img src="concordance_54_0.png" alt="png" /></p>

<p>But what about concordance?</p>

<p>Maybe our curve shape doesn&rsquo;t completely align with reality, but this is the Cox <em>Proportional Hazard</em> model. We&rsquo;re more interested in how well we&rsquo;ve captured the relationship between records&rsquo; relative risk, and by extension their ordering in terms of survival.</p>

<p>We&rsquo;ll store this as a standalone <code>Series</code> for our analysis.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">expectations</span> <span class="o">=</span> <span class="n">cph</span><span class="o">.</span><span class="n">predict_expectation</span><span class="p">(</span><span class="n">trimmed</span><span class="p">)</span></code></pre></div>
<p>For example, it&rsquo;s relatively straight-forward for us to look at the performance of the concordance index, by continent (with the sample size printed, for context).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">):</span>
    <span class="n">continent</span><span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">expectations</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
    
    <span class="n">ci</span> <span class="o">=</span> <span class="n">concordance_index</span><span class="p">(</span><span class="n">continent</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">],</span>
                           <span class="n">preds</span><span class="p">,</span>
                           <span class="n">continent</span><span class="p">[</span><span class="s1">&#39;observed&#39;</span><span class="p">])</span>
    
    <span class="k">print</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
          <span class="n">f</span><span class="s1">&#39;{ci:.3f}&#39;</span><span class="p">,</span>
          <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">))</span></code></pre></div>
<pre><code>Africa     0.608 314
Americas   0.476 412
Asia       0.682 398
Europe     0.549 576
Oceania    0.516 108
</code></pre>

<p>To the degree that we&rsquo;re doing a decent job at predicting death orders, it looks like our Asia and Africa results are propping up poor predictions elsewhere&ndash; worse than random (<code>.5</code>) in the Americas.</p>

<h3 id="time">Time?</h3>

<p>Curiously, though, this isn&rsquo;t to say that our model isn&rsquo;t doing <em>something</em> right.</p>

<p>If we now consider that &ldquo;time-to-death&rdquo; is a continuous variable, we can look at a more-traditional measure of model fit and investigate the Mean Squared Error by continent (with concordance left in, for context)</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;CI&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
      <span class="s1">&#39;MSE&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="s1">&#39;Count&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">):</span>
    <span class="n">continent</span><span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">expectations</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
    
    <span class="n">ci</span> <span class="o">=</span> <span class="n">concordance_index</span><span class="p">(</span><span class="n">continent</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">],</span>
                           <span class="n">preds</span><span class="p">,</span>
                           <span class="n">continent</span><span class="p">[</span><span class="s1">&#39;observed&#39;</span><span class="p">])</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">continent</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">],</span> 
                             <span class="n">preds</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
          <span class="n">f</span><span class="s1">&#39;{ci:.3f}&#39;</span><span class="p">,</span>
          <span class="n">f</span><span class="s1">&#39;{mse:.3f}&#39;</span><span class="p">,</span>
          <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">))</span></code></pre></div>
<pre><code>           CI    MSE    Count
Africa     0.608 74.030 314
Americas   0.476 28.611 412
Asia       0.682 53.970 398
Europe     0.549 18.923 576
Oceania    0.516 33.182 108
</code></pre>

<p>Hey, look at that&ndash; despite poor Concordance scores in the Americas and Europe, our MSE outperforms Asia and Africa, where we were celebrating model fit just a second ago.</p>

<p>Chasing down where we&rsquo;re underperforming by <em>both</em> metrics can lead to discovery and creation of better variables. So let&rsquo;s pare down our dataset to records where we have observed values and dig in.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;observed&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span></code></pre></div>
<p>To visualize patterns in our MSE, let&rsquo;s look at the raw difference between our predicted and observed deaths. This can be done in a couple of ways.</p>

<p>Looking at this in terms of volume, we might make a note to see if there&rsquo;s a commonality between Africa and Asia that we can use to rein in the kurtosis.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;observed&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span>

<span class="k">for</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">group</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">observed</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">),</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">expectations</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span></code></pre></div>
<p><img src="concordance_64_0.png" alt="png" /></p>

<p>Or with some simple box plots, we better-see the skew behavior</p>

<ul>
<li>Asia and Africa have outliers on both sides</li>
<li>Americas and Europe have longer-tailed errors</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">observed</span><span class="p">[</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">],</span>
            <span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">expectations</span><span class="p">),</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span></code></pre></div>
<p><img src="concordance_66_0.png" alt="png" /></p>

<p>Americas looks particularly offensive. Filtering down to just that continent and whipping up some KM curves by <code>region</code>, we can see that there&rsquo;s a pretty marked difference in the Caribbean.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">kmf</span> <span class="o">=</span> <span class="n">KaplanMeierFitter</span><span class="p">()</span>

<span class="n">americas</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;un_continent_name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Americas&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">americas</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;un_region_name&#39;</span><span class="p">):</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">])</span>
    <span class="n">kmf</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">ci_show</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></div>
<p><img src="concordance_68_0.png" alt="png" /></p>

<p>Which is the result of some serious outlier behavior.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">lifelines.plotting</span> <span class="kn">import</span> <span class="n">plot_lifetimes</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">filterwarnings</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plot_lifetimes</span><span class="p">(</span><span class="n">americas</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span></code></pre></div>
<p><img src="concordance_70_0.png" alt="png" /></p>

<p>Now who could that be?</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">americas</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">americas</span><span class="p">[</span><span class="s1">&#39;duration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span></code></pre></div>
<pre><code>ctryname                                                      Cuba
cowcode2                                                        40
politycode                                                      40
un_region_name                                           Caribbean
un_continent_name                                         Americas
ehead                                             Fidel Castro Ruz
leaderspellreg       Fidel Castro Ruz.Cuba.1959.2005.Civilian Dict
democracy                                            Non-democracy
regime                                               Civilian Dict
start_year                                                    1959
duration                                                        47
observed                                                         1
regime_type                                                   Dict
decade                                                        1950
Name: 375, dtype: object
</code></pre>

<p>Egads</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/rawhide.jpg&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="concordance_74_0.jpeg" alt="jpeg" /></p>

<h3 id="now-wait-a-minute">Now Wait a Minute</h3>

<p>Of course, it&rsquo;s worth noting that if we wanted a model that scored well in terms of MSE, we should have trained on MSE.</p>

<p>To restate a notion we had above, the Cox Proportional Hazard model is designed to optimize how we stack rank records by their hazard. Full stop.</p>

<p>If we were instead interested in accuracy of survival prediction, it&rsquo;d be more appropriate to use a method that duration as a target. Which, of course, then undervalues sorting and concordance.</p>

<p>It&rsquo;s all about defining the right objective for your application and picking the appropriate model. The same author as the top of this notebook has <a href="https://medium.com/analytics-vidhya/churn-prediction-in-a-telco-70ba5aa12f70">a great notebook exploring this idea.</a></p>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error or bug?</h4>
          <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/napsterinblue/notes/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/napsterinblue'>Twitter</a>.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 185 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
