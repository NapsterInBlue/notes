{"cells": [{"cell_type": "raw", "metadata": {}, "source": ["---\n", "title: \"Adding Dropout\"\n", "author: \"Chris Albon\"\n", "date: 2017-12-20T11:53:49-07:00\n", "description: \"How to add dropout to a neural networking for deep learning in Python..\"\n", "type: technical_note\n", "draft: false\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a alt=\"Dropout\" href=\"https://machinelearningflashcards.com\">\n", "    <img src=\"/images/machine_learning_flashcards/Dropout_print.png\" class=\"flashcard center-block\">\n", "</a>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["# Load libraries\n", "import numpy as np\n", "from keras.datasets import imdb\n", "from keras.preprocessing.text import Tokenizer\n", "from keras import models\n", "from keras import layers\n", "\n", "# Set random seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load IMDB Movie Review Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Set the number of features we want\n", "number_of_features = 1000\n", "\n", "# Load data and target vector from movie review data\n", "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n", "\n", "# Convert movie review data to a one-hot encoded feature matrix\n", "tokenizer = Tokenizer(num_words=number_of_features)\n", "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n", "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Construct Neural Network Architecture With Dropout Layer\n", "\n", "In Keras, we can implement dropout by added `Dropout` layers into our network architecture. Each `Dropout` layer will drop a user-defined hyperparameter of units in the previous layer every batch. Remember in Keras the input layer is assumed to be the first layer and not added using the `add`. Therefore, if we want to add dropout to the input layer, the layer we add in our is a dropout layer. This layer contains both the proportion of the input layer's units to drop `0.2` and `input_shape` defining the shape of the observation data. Next, after we add a dropout layer with `0.5` after each of the hidden layers."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Start neural network\n", "network = models.Sequential()\n", "\n", "# Add a dropout layer for input layer\n", "network.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu'))\n", "\n", "# Add a dropout layer for previous hidden layer\n", "network.add(layers.Dropout(0.5))\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=16, activation='relu'))\n", "\n", "# Add a dropout layer for previous hidden layer\n", "network.add(layers.Dropout(0.5))\n", "\n", "# Add fully connected layer with a sigmoid activation function\n", "network.add(layers.Dense(units=1, activation='sigmoid'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compile Neural Network"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='binary_crossentropy', # Cross-entropy\n", "                optimizer='rmsprop', # Root Mean Square Propagation\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Neural Network"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Train neural network\n", "history = network.fit(train_features, # Features\n", "                      train_target, # Target vector\n", "                      epochs=3, # Number of epochs\n", "                      verbose=0, # No output\n", "                      batch_size=100, # Number of observations per batch\n", "                      validation_data=(test_features, test_target)) # Data for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}