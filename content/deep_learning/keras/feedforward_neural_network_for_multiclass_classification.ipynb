{"cells": [{"cell_type": "raw", "metadata": {}, "source": ["---\n", "title: \"Feedforward Neural Network For Multiclass Classification\"\n", "author: \"Chris Albon\"\n", "date: 2017-12-20T11:53:49-07:00\n", "description: \"How to use Keras to train a feedforward neural network for multiclass classification in Python.\"\n", "type: technical_note\n", "draft: false\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Using TensorFlow backend.\n"]}], "source": ["# Load libraries\n", "import numpy as np\n", "from keras.datasets import reuters\n", "from keras.utils.np_utils import to_categorical\n", "from keras.preprocessing.text import Tokenizer\n", "from keras import models\n", "from keras import layers\n", "\n", "# Set random seed\n", "np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Movie Review Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Set the number of features we want\n", "number_of_features = 5000\n", "\n", "# Load feature and target data\n", "(train_data, train_target_vector), (test_data, test_target_vector) = reuters.load_data(num_words=number_of_features)\n", "\n", "# Convert feature data to a one-hot encoded feature matrix\n", "tokenizer = Tokenizer(num_words=number_of_features)\n", "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n", "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\n", "\n", "# One-hot encode target vector to create a target matrix\n", "train_target = to_categorical(train_target_vector)\n", "test_target = to_categorical(test_target_vector)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Construct Neural Network Architecture"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this example we use a loss function suited to multi-class classification, the categorical cross-entropy loss function, `categorical_crossentropy`."]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Start neural network\n", "network = models.Sequential()\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=100, activation='relu', input_shape=(number_of_features,)))\n", "\n", "# Add fully connected layer with a ReLU activation function\n", "network.add(layers.Dense(units=100, activation='relu'))\n", "\n", "# Add fully connected layer with a softmax activation function\n", "network.add(layers.Dense(units=46, activation='softmax'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compile Feedforward Neural Network"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Compile neural network\n", "network.compile(loss='categorical_crossentropy', # Cross-entropy\n", "                optimizer='rmsprop', # Root Mean Square Propagation\n", "                metrics=['accuracy']) # Accuracy performance metric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Feedforward Neural Network"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Train neural network\n", "history = network.fit(train_features, # Features\n", "                      train_target, # Target vector\n", "                      epochs=3, # Three epochs\n", "                      verbose=0, # No output\n", "                      batch_size=100, # Number of observations per batch\n", "                      validation_data=(test_features, test_target)) # Data to use for evaluation"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 2}