{"cells": [{"cell_type": "raw", "metadata": {}, "source": ["---\n", "title: \"Titanic Competition With Random Forest\"\n", "author: \"Chris Albon\"\n", "date: 2017-12-20T11:53:49-07:00\n", "description: \"Python code to make a submission to the titanic competition using a random forest.\"\n", "type: technical_note\n", "draft: false\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn import preprocessing\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import GridSearchCV, cross_val_score\n", "import csv as csv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get The Data\n", "\n", "You can get the data on [Kaggle's site](https://www.kaggle.com/c/titanic)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the data\n", "train = pd.read_csv('data/train.csv')\n", "test = pd.read_csv('data/test.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Cleaning"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create a list of the features we will eventually want for our model\n", "features = ['Age', 'SibSp','Parch','Fare','male','embarked_Q','embarked_S','Pclass_2', 'Pclass_3']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sex\n", "\n", "Here we convert the gender labels (`male`, `female`) into a dummy variable (`1`, `0`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create an encoder\n", "sex_encoder = preprocessing.LabelEncoder()\n", "\n", "# Fit the encoder to the train data so it knows that male = 1\n", "sex_encoder.fit(train['Sex'])\n", "\n", "# Apply the encoder to the training data\n", "train['male'] = sex_encoder.transform(train['Sex'])\n", "\n", "# Apply the encoder to the training data\n", "test['male'] = sex_encoder.transform(test['Sex'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Embarked"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Convert the Embarked training feature into dummies using one-hot\n", "# and leave one first category to prevent perfect collinearity\n", "train_embarked_dummied = pd.get_dummies(train[\"Embarked\"], prefix='embarked', drop_first=True)\n", "\n", "# Convert the Embarked test feature into dummies using one-hot\n", "# and leave one first category to prevent perfect collinearity\n", "test_embarked_dummied = pd.get_dummies(test[\"Embarked\"], prefix='embarked', drop_first=True)\n", "\n", "# Concatenate the dataframe of dummies with the main dataframes\n", "train = pd.concat([train, train_embarked_dummied], axis=1)\n", "test = pd.concat([test, test_embarked_dummied], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Social Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Convert the Pclass training feature into dummies using one-hot\n", "# and leave one first category to prevent perfect collinearity\n", "train_Pclass_dummied = pd.get_dummies(train[\"Pclass\"], prefix='Pclass', drop_first=True)\n", "\n", "# Convert the Pclass test feature into dummies using one-hot\n", "# and leave one first category to prevent perfect collinearity\n", "test_Pclass_dummied = pd.get_dummies(test[\"Pclass\"], prefix='Pclass', drop_first=True)\n", "\n", "# Concatenate the dataframe of dummies with the main dataframes\n", "train = pd.concat([train, train_Pclass_dummied], axis=1)\n", "test = pd.concat([test, test_Pclass_dummied], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Impute Missing Values\n", "\n", "A number of values of the `Age` feature are missing and will prevent the random forest to train. We get around this we will fill in missing values with the mean value of age (a useful fiction)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Age"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create an imputer object\n", "age_imputer = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n", "\n", "# Fit the imputer object on the training data\n", "age_imputer.fit(train['Age'].reshape(-1, 1))\n", "\n", "# Apply the imputer object to the training and test data\n", "train['Age'] = age_imputer.transform(train['Age'].reshape(-1, 1))\n", "test['Age'] = age_imputer.transform(test['Age'].reshape(-1, 1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Fare"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create an imputer object\n", "fare_imputer = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n", "\n", "# Fit the imputer object on the training data\n", "fare_imputer.fit(train['Fare'].reshape(-1, 1))\n", "\n", "# Apply the imputer object to the training and test data\n", "train['Fare'] = fare_imputer.transform(train['Fare'].reshape(-1, 1))\n", "test['Fare'] = fare_imputer.transform(test['Fare'].reshape(-1, 1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Search For Optimum Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create a dictionary containing all the candidate values of the parameters\n", "parameter_grid = dict(n_estimators=list(range(1, 5001, 1000)),\n", "                      criterion=['gini','entropy'],\n", "                      max_features=list(range(1, len(features), 2)),\n", "                      max_depth= [None] + list(range(5, 25, 1)))\n", "\n", "# Creata a random forest object\n", "random_forest = RandomForestClassifier(random_state=0, n_jobs=-1)\n", "\n", "# Create a gridsearch object with 5-fold cross validation, and uses all cores (n_jobs=-1)\n", "clf = GridSearchCV(estimator=random_forest, param_grid=parameter_grid, cv=5, verbose=1, n_jobs=-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Nest the gridsearchCV in a 3-fold CV for model evaluation\n", "cv_scores = cross_val_score(clf, train[features], train['Survived'])\n", "\n", "# Print results\n", "print('Accuracy scores:', cv_scores)\n", "print('Mean of score:', np.mean(cv_scores))\n", "print('Variance of scores:', np.var(cv_scores))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Retrain The Random Forest With The Optimum Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Retrain the model on the whole dataset\n", "clf.fit(train[features], train['Survived'])\n", "\n", "# Predict who survived in the test dataset\n", "predictions = clf.predict(test[features])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create The Kaggle Submission"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Grab the passenger IDs\n", "ids = test['PassengerId'].values\n", "\n", "# Create a csv\n", "submission_file = open(\"submission.csv\", \"w\")\n", "\n", "# Write to that csv\n", "open_file_object = csv.writer(submission_file)\n", "\n", "# Write the header of the csv\n", "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n", "\n", "# Write the rows of the csv\n", "open_file_object.writerows(zip(ids, predictions))\n", "\n", "# Close the file\n", "submission_file.close()"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.3"}}, "nbformat": 4, "nbformat_minor": 1}