{"cells": [{"cell_type": "raw", "metadata": {}, "source": ["---\n", "title: \"Remove Stop Words\"\n", "author: \"Chris Albon\"\n", "date: 2017-12-20T11:53:49-07:00\n", "description: \"How to remove stop words from unstructured text data for machine learning in Python.\"\n", "type: technical_note\n", "draft: false\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminaries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[nltk_data] Downloading package stopwords to\n", "[nltk_data]     /Users/chrisalbon/nltk_data...\n", "[nltk_data]   Package stopwords is already up-to-date!\n"]}, {"data": {"text/plain": ["True"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["# Load library\n", "from nltk.corpus import stopwords\n", "\n", "# You will have to download the set of stop words the first time\n", "import nltk\n", "nltk.download('stopwords')"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Create Word Tokens"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Create word tokens\n", "tokenized_words = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Load Stop Words"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": ["['i', 'me', 'my', 'myself', 'we']"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["# Load stop words\n", "stop_words = stopwords.words('english')\n", "\n", "# Show stop words\n", "stop_words[:5]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Remove Stop Words"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["['going', 'go', 'store', 'park']"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# Remove stop words\n", "[word for word in tokenized_words if word not in stop_words]"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.3"}}, "nbformat": 4, "nbformat_minor": 1}